{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opiod Prescription Project: Classification\n",
    "* _Data from Kaggle_: https://www.kaggle.com/apryor6/us-opiate-prescriptions  \n",
    "* _Classification based on Jason Liu's Notebook_: https://www.kaggle.com/jiashenliu/quick-and-dirty-attempt-on-voting-classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd  # DataFrame, Series\n",
    "import numpy as np  # Scientific Computing Packages - Array\n",
    "import re  # Regularized Expression\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  # Stats Visualization Library, wraps on top of matplotlib\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataframe of opioid drugs and their generic brand equivalents\n",
    "opioid = pd.read_csv(\"input/opioids.csv\")\n",
    "\n",
    "# Dataframe of states, total populations, deaths, and state abbrev.\n",
    "overdose = pd.read_csv(\"input/overdoses.csv\")\n",
    "\n",
    "# Dataframe of prescribers and features below\n",
    "prescriber = pd.read_csv(\"input/prescriber-info.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features in prescriber\n",
    "* **NPI** â€“ unique National Provider Identifier number  \n",
    "* **Gender** - (M/F)  \n",
    "* **State**  - U.S. State by abbreviation  \n",
    "* **Credentials** - set of initials indicative of medical degree  \n",
    "* **Specialty** - description of type of medicinal practice  \n",
    "* A long list of drugs with numeric values indicating the total number of prescriptions written for the year by that individual  \n",
    "* **Opioid.Prescriber** - a boolean label indicating whether or not that individual prescribed opiate drugs more than 10 times in the year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Pre-processing\n",
    "For classification, we will transform the features into all numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Full list of all opioid drugs\n",
    "name = opioid['Drug Name']\n",
    "\n",
    "# Rename without spaces or \"-\"s\n",
    "new_name = name.apply(lambda x: re.sub(\"/ |-\", \".\", str(x)))\n",
    "\n",
    "# List of all drugs that were prescribed, NPI, Gender, State, Specialty, etc\n",
    "col = prescriber.columns\n",
    "\n",
    "abandoned_var = set(col).intersection(set(new_name))\n",
    "keep_var = []\n",
    "\n",
    "# keep_var holds all opioids that are actually prescribed and categorical data\n",
    "for each in col:\n",
    "    if each in abandoned_var:\n",
    "        pass\n",
    "    else:\n",
    "        keep_var.append(each)\n",
    "        \n",
    "pres = prescriber[keep_var]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 80/20 train-test split\n",
    "train, test = train_test_split(pres, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 251)\n",
      "(5000, 251)\n"
     ]
    }
   ],
   "source": [
    "# test should be 1/4 (20/80) the size of train\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anepomu1/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/anepomu1/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "category = ['Gender', 'State', 'Credentials', 'Specialty']\n",
    "\n",
    "for col in category:\n",
    "    train[col] = pd.factorize(train[col], sort=True)[0]\n",
    "    test[col] = pd.factorize(test[col], sort=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>State</th>\n",
       "      <th>Credentials</th>\n",
       "      <th>Specialty</th>\n",
       "      <th>ABILIFY</th>\n",
       "      <th>ACYCLOVIR</th>\n",
       "      <th>ADVAIR.DISKUS</th>\n",
       "      <th>AGGRENOX</th>\n",
       "      <th>ALENDRONATE.SODIUM</th>\n",
       "      <th>ALLOPURINOL</th>\n",
       "      <th>...</th>\n",
       "      <th>VERAPAMIL.ER</th>\n",
       "      <th>VESICARE</th>\n",
       "      <th>VOLTAREN</th>\n",
       "      <th>VYTORIN</th>\n",
       "      <th>WARFARIN.SODIUM</th>\n",
       "      <th>XARELTO</th>\n",
       "      <th>ZETIA</th>\n",
       "      <th>ZIPRASIDONE.HCL</th>\n",
       "      <th>ZOLPIDEM.TARTRATE</th>\n",
       "      <th>Opioid.Prescriber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23311</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>594</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23623</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>196</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>431</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12645</th>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>431</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533</th>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>344</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Gender  State  Credentials  Specialty  ABILIFY  ACYCLOVIR  \\\n",
       "23311       1     11          594         62        0          0   \n",
       "23623       0     24          196         23        0          0   \n",
       "1020        1     47          431         39        0          0   \n",
       "12645       1     37          431        103        0          0   \n",
       "1533        1     55          344         66        0          0   \n",
       "\n",
       "       ADVAIR.DISKUS  AGGRENOX  ALENDRONATE.SODIUM  ALLOPURINOL  \\\n",
       "23311              0         0                   0            0   \n",
       "23623             33         0                   0           19   \n",
       "1020               0         0                  64           62   \n",
       "12645              0         0                   0            0   \n",
       "1533               0         0                   0            0   \n",
       "\n",
       "             ...          VERAPAMIL.ER  VESICARE  VOLTAREN  VYTORIN  \\\n",
       "23311        ...                     0         0         0        0   \n",
       "23623        ...                     0         0         0        0   \n",
       "1020         ...                    16         0        14        0   \n",
       "12645        ...                     0        22         0        0   \n",
       "1533         ...                     0         0         0        0   \n",
       "\n",
       "       WARFARIN.SODIUM  XARELTO  ZETIA  ZIPRASIDONE.HCL  ZOLPIDEM.TARTRATE  \\\n",
       "23311                0        0      0                0                  0   \n",
       "23623               15        0      0                0                 53   \n",
       "1020               128        0     11                0                 71   \n",
       "12645                0        0      0                0                  0   \n",
       "1533                 0        0      0                0                  0   \n",
       "\n",
       "       Opioid.Prescriber  \n",
       "23311                  0  \n",
       "23623                  1  \n",
       "1020                   1  \n",
       "12645                  0  \n",
       "1533                   1  \n",
       "\n",
       "[5 rows x 250 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = train.iloc[:, 1:251]\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Try Different Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Repeat features from above\n",
    "features = train.iloc[:, 1:251]\n",
    "\n",
    "# What are we training for?\n",
    "target = train['Opioid.Prescriber']\n",
    "\n",
    "# Names and accuracies of models to be tested\n",
    "Name = []\n",
    "Accuracy = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Models to Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = LogisticRegression(random_state=22, C=0.000000001, solver='liblinear', max_iter=200)\n",
    "m2 = GaussianNB()\n",
    "m3 = RandomForestClassifier(n_estimators=200, random_state=22)\n",
    "m4 = GradientBoostingClassifier(n_estimators=200)\n",
    "m5 = KNeighborsClassifier()\n",
    "m6 = DecisionTreeClassifier()\n",
    "m7 = LinearDiscriminantAnalysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess Models' Accuracy Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.589000 of model Logistic Regression\n",
      "Accuracy: 0.999850 of model Naive Bayes\n",
      "Accuracy: 0.999800 of model Random Forest\n",
      "Accuracy: 1.000000 of model Gradient Boosting\n",
      "Accuracy: 0.769900 of model KNN\n",
      "Accuracy: 1.000000 of model Decision Tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anepomu1/anaconda/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/Users/anepomu1/anaconda/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/Users/anepomu1/anaconda/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/Users/anepomu1/anaconda/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/Users/anepomu1/anaconda/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.723000 of model LDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anepomu1/anaconda/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/Users/anepomu1/anaconda/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/Users/anepomu1/anaconda/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/Users/anepomu1/anaconda/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/Users/anepomu1/anaconda/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.999800 of model Ensemble\n"
     ]
    }
   ],
   "source": [
    "# Create an ensemble and score them based on accuracy to vote for the \n",
    "    # best classifier\n",
    "Ensemble_model = VotingClassifier(estimators=[('lr', m1), \n",
    "                                              ('gn', m2), \n",
    "                                              ('rf', m3), \n",
    "                                              ('gb', m4), \n",
    "                                              ('kn', m5), \n",
    "                                              ('dt', m6), \n",
    "                                              ('lda', m7)], \n",
    "                                  voting='hard')\n",
    "\n",
    "for model, label in zip([m1, m2, m3, m4, m5, m6, m7, Ensemble_model],\n",
    "                       ['Logistic Regression', 'Naive Bayes', 'Random Forest', \n",
    "                        'Gradient Boosting', 'KNN', 'Decision Tree', 'LDA', \n",
    "                        'Ensemble']):\n",
    "    scores = cross_val_score(model, features, target, cv=5, scoring='accuracy')\n",
    "    Accuracy.append(scores.mean())\n",
    "    Name.append(model.__class__.__name__)\n",
    "    print(\"Accuracy: %f of model %s\" % (scores.mean(),label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Models with Accuracy below 80%, re-ensemble the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.999850 of model Naive Bayes\n",
      "Accuracy: 0.999800 of model Random Forest\n",
      "Accuracy: 1.000000 of model Gradient Boosting\n",
      "Accuracy: 1.000000 of model Decision Tree\n",
      "Accuracy: 1.000000 of model Ensemble\n"
     ]
    }
   ],
   "source": [
    "Name_2 = []\n",
    "Accuracy_2 = []\n",
    "\n",
    "Ensemble_model_2 = VotingClassifier(estimators=[('gn', m2), \n",
    "                                                ('rf', m3), \n",
    "                                                ('gb', m4),  \n",
    "                                                ('dt', m6)],  \n",
    "                                      voting='hard')\n",
    "\n",
    "for model, label in zip([m2, m3, m4, m6, Ensemble_model_2], \n",
    "                        ['Naive Bayes', 'Random Forest', \n",
    "                         'Gradient Boosting', 'Decision Tree', \n",
    "                         'Ensemble']):\n",
    "    scores = cross_val_score(model, features, target, cv=5, scoring='accuracy')\n",
    "    Accuracy_2.append(scores.mean())\n",
    "    Name_2.append(model.__class__.__name__)\n",
    "    print(\"Accuracy: %f of model %s\" % (scores.mean(),label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate with Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (5000,243) (250,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-83f2c901dd39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclassifiers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meach\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m244\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Opioid.Prescriber'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mName_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meach\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/anepomu1/anaconda/lib/python3.6/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \"\"\"\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mjll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/anepomu1/anaconda/lib/python3.6/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_joint_log_likelihood\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mjointi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_prior_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0mn_ij\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m             n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) /\n\u001b[0m\u001b[1;32m    430\u001b[0m                                  (self.sigma_[i, :]), 1)\n\u001b[1;32m    431\u001b[0m             \u001b[0mjoint_log_likelihood\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjointi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn_ij\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (5000,243) (250,) "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "classifiers = [m2, m3, m4, m6, Ensemble_model_2]\n",
    "out_sample_accuracy = []\n",
    "Name_2 = []\n",
    "\n",
    "for each in classifiers:\n",
    "    fit = each.fit(features,target)\n",
    "    pred = fit.predict(test.iloc[:, 1:244])\n",
    "    accuracy = accuracy_score(test['Opioid.Prescriber'], pred)\n",
    "    Name_2.append(each.__class__.__name__)\n",
    "    out_sample_accuracy.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
